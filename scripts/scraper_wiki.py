import requests
from bs4 import BeautifulSoup
import re
from functools import lru_cache
from urllib.parse import quote

HEADERS = {
    "User-Agent": "Mozilla/5.0 (compatible; CityScraper/1.5; +https://example.com)"
}

@lru_cache(maxsize=None)
def get_ville_infos(nom_ville):
    """R√©cup√®re les infos principales d'une ville sur Wikip√©dia (fran√ßais)."""

    # üßπ 1. Nettoyage du nom : enlever arrondissement / chiffres / suffixes "e", "√®me", etc.
    ville_clean = (
        str(nom_ville)
        .strip()
        .title()
        .replace("Arrondissement", "")
        .replace("Arrond.", "")
        .replace("Arrond", "")
        .replace("·µâ·µê·µâ", "")
        .replace("·µâ", "")
        .replace("Eme", "")
        .replace("√àme", "")
        .replace("Er", "")
    )

    # Supprimer chiffres et suffixes type "e", "·µâ", "eme" qui suivent un chiffre
    ville_clean = re.sub(r"\d+\s*(?:er|eme|√®me|e)?", "", ville_clean, flags=re.IGNORECASE).strip()

    nom_enc = quote(ville_clean.replace(" ", "_"))
    url = f"https://fr.wikipedia.org/wiki/{nom_enc}"

    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        if response.status_code != 200:
            print(f"‚ö†Ô∏è Page Wikipedia non trouv√©e pour {nom_ville} (tentative avec {ville_clean})")
            return _empty_ville(nom_ville)
    except Exception as e:
        print(f"‚ùå Erreur lors de la requ√™te pour {nom_ville}: {e}")
        return _empty_ville(nom_ville)

    soup = BeautifulSoup(response.text, "html.parser")

    infobox = soup.find("table", {"class": "infobox"})
    population = superficie = densite = None

    if infobox:
        text = infobox.get_text(" ", strip=True).lower()
        text = text.replace("\xa0", " ").replace(",", ".").replace("  ", " ")

        pop_match = re.search(r"population[^\d]*([\d\s]{4,})", text)
        sup_match = re.search(r"superficie[^\d]*([\d\.]+)", text)
        den_match = re.search(r"densit√©[^\d]*([\d\s\.]+)", text)

        if pop_match:
            population = f"{_clean_number(pop_match.group(1))} hab."
        if sup_match:
            superficie = f"{_clean_number(sup_match.group(1))} km¬≤"
        if den_match:
            densite = f"{_clean_number(den_match.group(1))} hab/km¬≤"

    # üîπ Court r√©sum√© (nettoy√© + suppression prononciation)
    resume = ""
    for p in soup.select("p"):
        txt = p.get_text(" ", strip=True)
        if len(txt) > 100 and not txt.startswith("Cet article"):
            resume = _clean_resume(txt)
            break

    if not resume:
        resume = "‚ÑπÔ∏è Aucune information disponible."

    return {
        "ville": nom_ville,
        "population": population,
        "superficie": superficie,
        "densit√©": densite,
        "infos": resume,
    }


def _clean_number(s):
    """Nettoie un nombre : supprime espaces et caract√®res parasites."""
    return s.replace("\xa0", "").replace(" ", "").replace(".", ",")


def _clean_resume(txt):
    """Nettoie le paragraphe Wikip√©dia pour un texte lisible."""
    # Enlever les r√©f√©rences [1], [ 1 ], etc.
    txt = re.sub(r"\[\s*\d+\s*\]", "", txt)
    # Enlever les prononciations ou phon√©tiques
    txt = re.sub(r"\[.*?\]", "", txt)
    txt = re.sub(r"\(.*?prononc[√©e]?\s.*?\)", "", txt, flags=re.IGNORECASE)
    txt = re.sub(r"\(.*?pronon[√ßc]er.*?\)", "", txt, flags=re.IGNORECASE)
    txt = re.sub(r"prononc[√©e]?\s.*?(,|‚Äî|-)", "", txt, flags=re.IGNORECASE)
    txt = re.sub(r"‚Äî\s*", "", txt)
    txt = re.sub(r"/.*?/", "", txt)
    txt = re.sub(r"√âcouter", "", txt, flags=re.IGNORECASE)
    txt = re.sub(r"‚ìò", "", txt)
    txt = re.sub(r"\s*\[a\]\s*", "", txt)

    # üîπ Supprimer les parenth√®ses vides (comme "( )")
    txt = re.sub(r"\(\s*\)", "", txt)

    # üîπ Corriger doublons de mots ("est est", "la la", etc.)
    txt = re.sub(r"\b(\w+)\s+\1\b", r"\1", txt, flags=re.IGNORECASE)

    # Corriger les collages de mots
    txt = re.sub(r"([a-z√©√®√™√´√†√¢√Æ√Ø√¥√∂√ª√º√ß])([A-Z√â√à√ä√ã√Ä√Ç√é√è√î√ñ√õ√ú√á])", r"\1 \2", txt)
    txt = txt.replace("Villede", "Ville de ")
    txt = txt.replace("Franceainsi", "France ainsi ")
    txt = txt.replace("lacapitale", "la capitale ")
    txt = txt.replace("unecollectivit√©", "une collectivit√© ")
    txt = txt.replace("vingtarrondissements", "vingt arrondissements ")

    # Espaces et ponctuation
    txt = re.sub(r"\s+([,.;!?])", r"\1", txt)
    txt = re.sub(r"\s+", " ", txt).strip()

    # Tronquer √† 2 phrases max
    sentences = re.split(r"(?<=[.!?]) +", txt)
    return " ".join(sentences[:2]).strip()


def _empty_ville(nom_ville):
    return {
        "ville": nom_ville,
        "population": None,
        "superficie": None,
        "densit√©": None,
        "infos": "‚ÑπÔ∏è Aucune information disponible.",
    }


if __name__ == "__main__":
    print(get_ville_infos("Paris 15e arrondissement"))
    print(get_ville_infos("Marseille 3e"))
    print(get_ville_infos("Montpellier"))
    print(get_ville_infos("Lyon 7eme"))